import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torchsummary import summary
import math

class MaskedLinear(nn.Module):
    def __init__(self, in_features, out_features, mask):
        super(MaskedLinear, self).__init__()
        self.mask = mask
        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))
        self.bias = nn.Parameter(torch.Tensor(out_features))
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        fan_in, _= nn.init._calculate_fan_in_and_fan_out(self.weight)
        bound = 1 / math.sqrt(fan_in)
        nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, in_features):
        masked_weight = self.mask * self.weight
        return nn.functional.linear(in_features, masked_weight, self.bias)

# Group Masked Autoencoder (Group-MADE) implementation
class AutoMaskEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dims):
        super(AutoMaskEncoder, self).__init__()
        self.input_dim = input_dim
        self.hidden_dims = hidden_dims

    def encoder_layer(self):
        layers = nn.ModuleList()
        in_size = self.input_dim
        for out_size in enumerate(hidden_dims):
            mask = self.create_mask(in_size, input_dim)
            layer = MaskedLinear(in_size, out_size, mask)
            layers.append(layer)
            #self.layers.append(nn.ReLU())
            in_size = out_size
        return layers

    def decoder_layer(self):
        layers = nn.ModuleList()
        for out_size in reversed(hidden_dims):
            in_size = out_size
            mask = self.create_mask(in_size, out_size)
            layer = MaskedLinear(in_size, out_size, mask)
            self.layers.append(layer)
        return layers

    def create_mask(self, in_size, out_size):
        mask = torch.zeros((out_size, in_size))
        for i in range(out_size):
            mask[i, :i] = 1
        return mask

    def forward(self, x):
        encoded = self.encoder_layer(x)
        decoded = self.decoder_layer(encoded)
        return decoded

class MADE(nn.Module):
    def __init__(self, input_size, hidden_sizes):
        super(MADE, self).__init__()
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.L = len(hidden_sizes)

        self.layers = nn.ModuleList()
        self.output_layer = None

        in_size = input_size
        for l, out_size in enumerate(hidden_sizes):
            mask = self.create_mask(in_size, out_size)
            layer = MaskedLinear(in_size, out_size, mask)
            self.layers.append(layer)
            in_size = out_size

        mask = self.create_mask(in_size, input_size)
        self.output_layer = MaskedLinear(in_size, input_size, mask)

    def create_mask(self, in_size, out_size):
        mask = torch.zeros((out_size, in_size))
        for i in range(out_size):
            mask[i, :i] = 1 
        return mask

    def loss(self, x):
        output = self.forward(x)
        loss = nn.BCEWithLogitsLoss()(output, x)
        return loss

    def forward(self, x): 
        h = x 
        for layer in self.layers:
            h = layer(h)

        output = self.output_layer(h)
        return output

# Training
def train(model, train_data, num_epochs, batch_size, lr):
    optimizer = optim.Adam(model.parameters(), lr=lr)
    data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)

    for epoch in range(num_epochs):
        epoch_loss = 0.0
        for batch in data_loader:
            optimizer.zero_grad()
            inputs = batch.float()
            loss = model.loss(inputs)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(data_loader)}")

# Example usage
input_size = 128
hidden_sizes = [128, 128, 64, 64, 32]
num_epochs = 100
batch_size = 64
lr = 0.001

train_data = torch.randn(100, 640, 128)

# Create the MADE model
model = MADE(input_size, hidden_sizes)
#summary(model, input_size=[1, 640, 128])    

# Train the model
train(model, train_data, num_epochs, batch_size, lr)

# Generate samples
num_samples = 10

#def train():
#    input_dim = [320, 640]
#    hidden_dims = [128, 128, 64, 64, 32]
#    model = AutoMaskEncoder(input_dim, hidden_dims)
#    print(model)
#    summary(model, input_size=[1, 320, 640])    
